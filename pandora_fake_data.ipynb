{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6915063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\anita\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\anita\\anaconda3\\lib\\site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anita\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\anita\\anaconda3\\lib\\site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\anita\\anaconda3\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\anita\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\anita\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\anita\\anaconda3\\lib\\site-packages (from networkx->torch) (5.0.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\anita\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4bf81b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6d597de7ba89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_deterministic_algorithms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.bmm(torch.randn(2,2,2).to_sparse().cuda(), torch(2,2,2).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deec6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "my_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32, device=\"cpu\")\n",
    "print(my_tensor)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc22ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchgeometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78577642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "my_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32, device=\"cpu\")\n",
    "print(my_tensor)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f79f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459e03cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76495fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee071511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ca96cf4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in c:\\users\\anita\\anaconda3\\lib\\site-packages (19.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.1 in c:\\users\\anita\\anaconda3\\lib\\site-packages (from faker) (4.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\users\\anita\\anaconda3\\lib\\site-packages (from faker) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anita\\anaconda3\\lib\\site-packages (from python-dateutil>=2.4->faker) (1.15.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>date</th>\n",
       "      <th>prev_charm_count</th>\n",
       "      <th>this_charm_count</th>\n",
       "      <th>prev_bracelet_count</th>\n",
       "      <th>this_bracelet_count</th>\n",
       "      <th>prev_rings_count</th>\n",
       "      <th>this_rings_count</th>\n",
       "      <th>prev_necklace_count</th>\n",
       "      <th>this_necklace_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUSTOMER_3</td>\n",
       "      <td>3eb13b90-4668-4257-bdd6-40fb06671ad1</td>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUSTOMER_1</td>\n",
       "      <td>3b8faa18-37f8-488b-97fc-695a07a0ca6e</td>\n",
       "      <td>2023-07-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUSTOMER_7</td>\n",
       "      <td>cf36d58b-4737-4190-96da-1dac72ff5d2a</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUSTOMER_3</td>\n",
       "      <td>5be6128e-18c2-4797-a142-ea7d17be3111</td>\n",
       "      <td>2023-05-14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUSTOMER_2</td>\n",
       "      <td>a0ee89ae-d453-4d32-8b0d-bb418d5288f1</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>CUSTOMER_4</td>\n",
       "      <td>f2e2503a-b2d5-45d1-8706-f724bf83f2d4</td>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>CUSTOMER_3</td>\n",
       "      <td>a477e25a-e193-43a9-8f5c-365a27e83b87</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>CUSTOMER_14</td>\n",
       "      <td>420fd9a8-d45b-4e9b-b61e-c0ed8ddd2994</td>\n",
       "      <td>2023-08-11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>CUSTOMER_12</td>\n",
       "      <td>be3e1402-2008-4d4c-b379-85dffa59607b</td>\n",
       "      <td>2023-03-24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>CUSTOMER_2</td>\n",
       "      <td>7a37f3d6-77eb-4d89-b142-de87d109ffe5</td>\n",
       "      <td>2023-05-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customer_id                              order_id        date  \\\n",
       "0     CUSTOMER_3  3eb13b90-4668-4257-bdd6-40fb06671ad1  2023-03-28   \n",
       "1     CUSTOMER_1  3b8faa18-37f8-488b-97fc-695a07a0ca6e  2023-07-16   \n",
       "2     CUSTOMER_7  cf36d58b-4737-4190-96da-1dac72ff5d2a  2023-01-03   \n",
       "3     CUSTOMER_3  5be6128e-18c2-4797-a142-ea7d17be3111  2023-05-14   \n",
       "4     CUSTOMER_2  a0ee89ae-d453-4d32-8b0d-bb418d5288f1  2023-08-29   \n",
       "..           ...                                   ...         ...   \n",
       "995   CUSTOMER_4  f2e2503a-b2d5-45d1-8706-f724bf83f2d4  2023-04-27   \n",
       "996   CUSTOMER_3  a477e25a-e193-43a9-8f5c-365a27e83b87  2023-01-13   \n",
       "997  CUSTOMER_14  420fd9a8-d45b-4e9b-b61e-c0ed8ddd2994  2023-08-11   \n",
       "998  CUSTOMER_12  be3e1402-2008-4d4c-b379-85dffa59607b  2023-03-24   \n",
       "999   CUSTOMER_2  7a37f3d6-77eb-4d89-b142-de87d109ffe5  2023-05-02   \n",
       "\n",
       "     prev_charm_count  this_charm_count  prev_bracelet_count  \\\n",
       "0                 1.0               5.0                  3.0   \n",
       "1                 0.0               0.0                  4.0   \n",
       "2                 2.0               5.0                  6.0   \n",
       "3                 4.0               2.0                  5.0   \n",
       "4                 1.0               4.0                  0.0   \n",
       "..                ...               ...                  ...   \n",
       "995               4.0               3.0                  2.0   \n",
       "996               4.0               1.0                  0.0   \n",
       "997               4.0               2.0                  5.0   \n",
       "998               4.0               4.0                  3.0   \n",
       "999               5.0               5.0                  5.0   \n",
       "\n",
       "     this_bracelet_count  prev_rings_count  this_rings_count  \\\n",
       "0                    5.0               1.0               0.0   \n",
       "1                    1.0               1.0               5.0   \n",
       "2                    2.0               4.0               1.0   \n",
       "3                    5.0               2.0               4.0   \n",
       "4                    5.0               1.0               0.0   \n",
       "..                   ...               ...               ...   \n",
       "995                  3.0               0.0               5.0   \n",
       "996                  1.0               4.0               3.0   \n",
       "997                  3.0               5.0               2.0   \n",
       "998                  1.0               5.0               1.0   \n",
       "999                  3.0               4.0               0.0   \n",
       "\n",
       "     prev_necklace_count  this_necklace_count  \n",
       "0                    1.0                  3.0  \n",
       "1                    3.0                  3.0  \n",
       "2                    3.0                  2.0  \n",
       "3                    1.0                  3.0  \n",
       "4                    2.0                  1.0  \n",
       "..                   ...                  ...  \n",
       "995                  0.0                  2.0  \n",
       "996                  3.0                  5.0  \n",
       "997                  3.0                  4.0  \n",
       "998                  1.0                  4.0  \n",
       "999                  3.0                  5.0  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "!pip install faker\n",
    "\n",
    "from faker import Faker\n",
    "\n",
    "from random import randint \n",
    "import pandas as pd \n",
    "import os\n",
    " \n",
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    " \n",
    "def input_data(x,my_tensor,my_customer_data):\n",
    "   \n",
    "    data = pd.DataFrame()\n",
    "    Faker.seed(42)\n",
    "#     Customer_id, order_id, prev_charms_count, prev_bracelet_count, prev_ring_count,\n",
    "# this_order_charm_count, this_order_bracelet_count, this_order_ring_count\n",
    "    for i in range(0, x):\n",
    "        data.loc[i,'customer_id']  = fake.random_element(elements=(my_customer_data['customer_id']))\n",
    "        data.loc [i,'order_id']= fake.uuid4()\n",
    "        data.loc[i,'date']= fake.date_this_year()\n",
    "        for j in range(0,len(my_tensor)):\n",
    "            data.loc[i,'prev_' + my_tensor[j]+'_count'] = fake.random_int(min=0, max=10)\n",
    "            data.loc[i,'this_' + my_tensor[j]+'_count'] = fake.random_int(min=0, max=5)\n",
    "    return data.drop_duplicates()\n",
    "\n",
    "def process_data(df,my_tensor,my_customer_data):\n",
    "    for c in (range(len(my_customer_data))):\n",
    " \n",
    "        dc=df.loc[df['customer_id'] == my_customer_data.loc[c,'customer_id']]\n",
    "        dc_7=dc.sort_values(by=['customer_id', 'date'])\n",
    "#         print(\"BEFORE\")\n",
    "#         display(dc_7)\n",
    "#         Get the index_values which is the row number on the frame\n",
    "        index_values= list(dc_7.index.values)\n",
    "        for i in range(len(index_values)):\n",
    "            if i != 0:\n",
    "                for j in range(0,len(my_tensor)):\n",
    "                    dc_7.loc[index_values[i],'prev_' + my_tensor[j]+'_count'] = dc_7.loc[index_values[i-1],'this_' + my_tensor[j]+'_count']\n",
    "                    df.loc[index_values[i],'prev_' + my_tensor[j]+'_count'] = df.loc[index_values[i-1],'this_' + my_tensor[j]+'_count']\n",
    "#         print(\"AFTER\")\n",
    "#         display(dc_7)     \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "########  MAIN   ####################################  \n",
    "my_tensor =['charm', 'bracelet', 'rings', 'necklace']\n",
    "my_customer_data= pd.DataFrame()\n",
    "Faker.seed(42)\n",
    "for i in range(0,20):\n",
    "    my_customer_data.loc[i,'customer_id']= \"CUSTOMER_\" + str(i)\n",
    "# display(my_customer_data)\n",
    "    \n",
    "\n",
    "df=input_data(1000, my_tensor,my_customer_data)\n",
    "\n",
    "df_processed=process_data(df,my_tensor,my_customer_data)\n",
    "\n",
    "display(df_processed)\n",
    "os.makedirs('outputs', exist_ok=True)  \n",
    "\n",
    "df_processed.to_csv('outputs/out.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee36770e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922fafb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04134499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
